# ðŸŒŒ LYNX Complete Setup Guide - Step by Step

**Detailed instructions for Windows users** - Every command explained!

## ðŸ“‹ Prerequisites Check

First, verify you have the required software:

```powershell
# Check Node.js (need 20+)
node --version

# Check Python (need 3.11+)
python --version

# Check Docker
docker --version

# Check Git
git --version
```

If any are missing, install them first:
- **Node.js 20+**: https://nodejs.org/
- **Python 3.11+**: https://www.python.org/downloads/
- **Docker Desktop**: https://www.docker.com/products/docker-desktop/

## ðŸš€ Complete Setup Process

### Step 1: Project Setup (2 minutes)

```powershell
# Navigate to your projects folder
cd C:\Users\%USERNAME%\repos

# Clone the repository (if not already done)
# git clone <your-repo-url>
cd lynx

# Install Node.js dependencies
npm install
```

**What this does**: Downloads all JavaScript/TypeScript packages needed for the frontend and API.

### Step 2: Environment Configuration (1 minute)

```powershell
# Copy the environment template
copy .env.example .env

# View the .env file (optional)
type .env
```

**What this does**: Creates your local environment configuration. With SBERT, you don't need to edit anything - the defaults work!

**Your .env should look like this:**
```
# Database Configuration
DATABASE_URL="postgresql://lynx_user:lynx_password@localhost:5432/lynx_dev"
SUPABASE_URL="your-supabase-url"
SUPABASE_ANON_KEY="your-supabase-anon-key"
SUPABASE_SERVICE_ROLE_KEY="your-supabase-service-role-key"

# OpenAI Configuration (NOT NEEDED for SBERT!)
OPENAI_API_KEY="your-openai-api-key"

# ... other settings
```

### Step 3: Database Setup (3 minutes)

This is the most important part! We'll use Docker to run PostgreSQL with the pgvector extension.

```powershell
# Start the database container
npm run docker:up
```

**What this does**: 
- Downloads PostgreSQL with pgvector extension
- Creates a database named `lynx_dev`
- Sets up user `lynx_user` with password `lynx_password`
- Exposes database on port 5432

**Wait for database to initialize** (about 30 seconds). You should see:
```
âœ… lynx-postgres container started
âœ… lynx-redis container started
```

Now run the database migrations:

```powershell
# Navigate to the web app folder
cd apps\web

# Run database migrations to create tables
npm run db:migrate
```

**What this does**: Creates all the tables (concepts, embeddings, edges, node_positions) in your database.

**Expected output:**
```
âœ… Applying migrations...
âœ… Database schema updated
```

```powershell
# Go back to project root
cd ..\..
```

### Step 4: Python Environment Setup (5 minutes)

Now let's set up Python properly with a virtual environment:

```powershell
# Navigate to the ingestion scripts
cd scripts\ingestion

# Create a Python virtual environment
python -m venv venv

# Activate the virtual environment
venv\Scripts\activate
```

**What this does**: Creates an isolated Python environment so packages don't conflict with your system Python.

**You should see `(venv)` at the start of your command prompt now.**

### Step 5: Install Python Dependencies (10 minutes)

This step takes the longest because we're downloading PyTorch and SBERT:

```powershell
# Install PyTorch first (CPU version for compatibility)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu

# Install sentence-transformers (SBERT)
pip install sentence-transformers

# Install other dependencies
pip install -r requirements.txt
```

**What this does**:
- **PyTorch**: Machine learning framework (needed for SBERT)
- **sentence-transformers**: SBERT library for embeddings
- **Other packages**: Database drivers, data processing tools

**Expected downloads**:
- PyTorch: ~200MB
- SBERT models: ~90MB (downloaded on first use)
- Other packages: ~50MB

### Step 6: Test Database Connection (1 minute)

Let's verify the database is working:

```powershell
# Test database connection
python -c "import psycopg2; conn = psycopg2.connect('postgresql://lynx_user:lynx_password@localhost:5432/lynx_dev'); print('âœ… Database connection successful'); conn.close()"
```

**Expected output**: `âœ… Database connection successful`

If this fails, check:
- Docker Desktop is running
- Database container is up: `docker ps`
- No other PostgreSQL running on port 5432

### Step 7: Test Python Dependencies (1 minute)

```powershell
# Test all Python imports
python -c "
import requests
import pandas
import numpy
import sentence_transformers
import psycopg2
print('âœ… All Python dependencies working')
"
```

**Expected output**: `âœ… All Python dependencies working`

### Step 8: Run Test Pipeline (3 minutes)

Now let's test the complete pipeline with sample data:

```powershell
# Go back to project root (important!)
cd ..\..

# Run the test ingestion
python scripts\test-ingestion.py
```

**Expected output** (this will take 2-3 minutes):
```
ðŸ§ª Testing database connection...
âœ… Database connection working
ðŸ§ª Testing Wikipedia ingestion...
âœ… Fetched: Artificial intelligence
âœ… Fetched: Black hole
âœ… Fetched: DNA
âœ… Fetched: Quantum mechanics
âœ… Fetched: Leonardo da Vinci
âœ… Fetched 5 test concepts
ðŸ§ª Testing concept storage...
âœ… Concepts stored in database
ðŸ§ª Testing SBERT embedding generation...
Loading SBERT model: all-MiniLM-L6-v2
Downloading (â€¦)_Pooling/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 190/190
Downloading (â€¦)b85/.gitattributes: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 1.18k/1.18k
Downloading (â€¦)_modules.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 349/349
Downloading (â€¦)/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 612/612
Downloading (â€¦)ce_transformers.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 116/116
Downloading (â€¦)e1/.gitattributes: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 1.18k/1.18k
Downloading (â€¦)_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 684/684
Downloading (â€¦)pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 90.9M/90.9M
Downloading (â€¦)okenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 350/350
Downloading (â€¦)solve/main/vocab.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 232k/232k
Downloading (â€¦)/special_tokens_map.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 112/112
Downloading (â€¦)a8e1d/.gitattributes: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 1.18k/1.18k
Downloading (â€¦)1_Pooling/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆ| 190/190
âœ… SBERT model loaded successfully
Processing batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.34it/s]
âœ… Generated 5 embeddings
ðŸŽ‰ Pipeline test completed successfully!
ðŸ“Š Results: 5 concepts, 5 embeddings

ðŸŽ‰ Test passed! Your LYNX pipeline is working with SBERT.

Next steps:
1. Check http://localhost:3000/api/status to see updated counts
2. Try searching for 'artificial intelligence' in the web interface
3. Run full ingestion with: python scripts/ingestion/main.py --concepts 1000
4. No OpenAI API costs - SBERT runs locally! ðŸŽ†
```

### Step 9: Start the Frontend (1 minute)

```powershell
# Start the development server
npm run dev
```

**Expected output**:
```
â–² Next.js 14.0.0
- Local:        http://localhost:3000
- Network:      http://192.168.1.xxx:3000

âœ“ Ready in 2.3s
```

### Step 10: Test the Web Interface (2 minutes)

1. **Open your browser** and go to: `http://localhost:3000`

2. **You should see**:
   - ðŸŒŒ Beautiful galaxy-themed interface
   - ðŸ” Search bar at the top
   - ðŸ“Š Status bar showing "5 concepts â€¢ 5 embeddings â€¢ 0 edges"
   - ðŸŽ¨ Dark space-like background

3. **Test search**:
   - Type "artificial intelligence" in the search bar
   - You should see search results appear
   - Click on a result to see concept details in the right panel

4. **Test API directly**:
   - Visit: `http://localhost:3000/api/status`
   - Should return JSON with concept counts

## ðŸŽ¯ Verification Checklist

Check off each item as you complete it:

- âœ… Node.js dependencies installed (`npm install` succeeded)
- âœ… Environment file created (`.env` exists)
- âœ… Docker containers running (`docker ps` shows lynx-postgres)
- âœ… Database migrations applied (tables created)
- âœ… Python virtual environment activated (`(venv)` in prompt)
- âœ… Python dependencies installed (PyTorch, SBERT, etc.)
- âœ… Database connection test passed
- âœ… Test ingestion completed (5 concepts processed)
- âœ… Frontend loads at localhost:3000
- âœ… Search returns results for "artificial intelligence"

## ðŸ”§ Troubleshooting Common Issues

### Issue: `npm install` fails
**Solution**: 
```powershell
# Check Node.js version
node --version
# Should be 20.x.x or higher

# Clear npm cache if needed
npm cache clean --force
npm install
```

### Issue: Docker containers won't start
**Solution**:
```powershell
# Make sure Docker Desktop is running
# Check if ports are free
netstat -an | findstr :5432
netstat -an | findstr :6379

# If ports are in use, stop other services or change ports
```

### Issue: Database migration fails
**Solution**:
```powershell
# Reset database
npm run docker:down
npm run docker:up

# Wait 30 seconds, then try again
cd apps\web
npm run db:migrate
```

### Issue: Python virtual environment not working
**Solution**:
```powershell
# Make sure you're using the right Python command
python --version
# or try:
py --version

# Create venv with full path
python -m venv venv

# Activate with full path
.\venv\Scripts\activate
```

### Issue: PyTorch installation fails
**Solution**:
```powershell
# Install PyTorch separately with CPU-only version
pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu

# Then install other requirements
pip install sentence-transformers pandas numpy psycopg2-binary
```

### Issue: SBERT model download fails
**Solution**:
- Check internet connection
- The model is ~90MB, so it may take time
- If it fails, try running the test again - it will resume download

### Issue: Frontend shows errors
**Solution**:
```powershell
# Check browser console (F12)
# Common fixes:

# 1. Rebuild the frontend
npm run build

# 2. Clear browser cache (Ctrl+Shift+R)

# 3. Check if API is running
# Visit: http://localhost:3000/api/status
```

## ðŸŽ‰ Success! What You've Built

If all tests pass, you now have:

- ðŸŒŒ **Beautiful galaxy interface** with semantic search
- ðŸ—„ï¸ **PostgreSQL database** with pgvector for embeddings
- ðŸ¤– **SBERT embeddings** running locally (no API costs!)
- ðŸ” **Semantic search** that finds related concepts
- ðŸ“Š **Real-time status** monitoring
- ðŸ **Python pipeline** for data ingestion
- ðŸ’° **$0 API costs** for the MVP!

## ðŸš€ Next Steps

Now that everything works:

1. **Explore the interface** - try different searches
2. **Run larger ingestion**: `python scripts\ingestion\main.py --concepts 100`
3. **Check the database**: `cd apps\web && npm run db:studio`
4. **Review the code** - understand the architecture
5. **Start building features** - galaxy visualization, pathfinding, etc.

You're ready to build the knowledge galaxy! ðŸŒŸ
